{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the influence of the nature and wellbeing of a Country in its Co2 emissions\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "### Data sets\n",
    "This analysis is based on date extracted from [Gapminder](https://www.google.com/url?q=http://www.gapminder.org/data/&sa=D&ust=1532469042121000), a website that has collected a lot of\n",
    "information about how people live their lives in dierent countries, tracked across the years, and on a number of diferent indicators. \n",
    "\n",
    "I've focused my analysis on enviromental pollution and what influences it. \n",
    "\n",
    "The analysis consists of the following indicators:\n",
    " \n",
    "- [C02 Emission (tonnes per person)](https://cdiac.ess-dive.lbl.gov/)\n",
    "Carbon dioxide emissions from the burning of fossil fuels (metric tonnes of C02 per person). \n",
    "This indicator has been chosen to analyze the ecological behaviour of each country, the more Co2 emissions a country makes the less ecological friendly it is.  \n",
    "\n",
    "- [Forest coverage(%)](https://www.fao.org/forestry/sofo/en/)\n",
    "Percentage of total land area that has been covered with forest during the given year.\n",
    "This indicator has been chosen to analyze the amount of nature that surrounds the people in each country, and also to see its evolution accross the years. \n",
    "\n",
    "- [Democracy score](http://www.systemicpeace.org/inscrdata.html)\n",
    "Summary measure of a country's democratic and free nature in all independent countries with total population greater than 500,000 in 2018. \n",
    "For a better understanding of this index, -10 is the lowest value and 10 the highest. \n",
    "This indicator has been chosen to understand the influece of the people on the countries' decisions. \n",
    "_This dataset was extracted directly from the sorucelink, since it was a newer version than the one provided in gapminder._\n",
    "\n",
    "- [Human Development Index (HDI)](http://hdr.undp.org/en/indicators/137506)\n",
    "Index used to rank countries by level of \"human development\". It contains three dimensions: health level, educational level and living standard. \n",
    "For a better understanding of this index, the score can be understood the following way: \n",
    "\n",
    "| Human development | Score   |\n",
    "|-----------------------------|-------------|\n",
    "| Very high | >= 0.800    |\n",
    "| High | 0.700–0.799 |\n",
    "| Medium | 0.550–0.699 |\n",
    "| Low | < 0.550     |\n",
    "\n",
    "### Objective\n",
    "\n",
    "The main purpose of this analysis is to understand if the wellbeing of the society (HDI), the democratic system (polity) or the surrounding nature (forest coverage) impact somehow its ecological impact (emissions of Co2). \n",
    "Do countries with a better democratic system, understood as a more influence of the people in its decisions, less Co2 emissions? Within these countries, does the wellbeing have an impact? Do people with a better education, health system and living standard impact on its countries ecological impact?\n",
    "And lastly, has the amount of nature that surrounds these people impact on their actions? \n",
    "\n",
    "With the last variable, forest coverage, I also want to see if there is any relation between the increase of Co2 emissions and the decrease of the forest coverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "\n",
    "### General Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C02 Emission (tonnes per person) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>...</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3800</td>\n",
       "      <td>1.2800</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.460</td>\n",
       "      <td>1.480</td>\n",
       "      <td>1.560</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.730</td>\n",
       "      <td>1.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>2.9900</td>\n",
       "      <td>3.1900</td>\n",
       "      <td>3.160</td>\n",
       "      <td>3.420</td>\n",
       "      <td>3.300</td>\n",
       "      <td>3.290</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.510</td>\n",
       "      <td>3.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>6.5200</td>\n",
       "      <td>6.430</td>\n",
       "      <td>6.120</td>\n",
       "      <td>6.120</td>\n",
       "      <td>5.870</td>\n",
       "      <td>5.92</td>\n",
       "      <td>5.900</td>\n",
       "      <td>5.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>1.180</td>\n",
       "      <td>1.230</td>\n",
       "      <td>1.240</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8100</td>\n",
       "      <td>4.9100</td>\n",
       "      <td>5.1400</td>\n",
       "      <td>5.190</td>\n",
       "      <td>5.450</td>\n",
       "      <td>5.540</td>\n",
       "      <td>5.360</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.360</td>\n",
       "      <td>5.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1400</td>\n",
       "      <td>4.4300</td>\n",
       "      <td>4.3800</td>\n",
       "      <td>4.680</td>\n",
       "      <td>4.410</td>\n",
       "      <td>4.560</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.460</td>\n",
       "      <td>4.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4600</td>\n",
       "      <td>1.4800</td>\n",
       "      <td>1.7300</td>\n",
       "      <td>1.910</td>\n",
       "      <td>1.510</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.710</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17.3000</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>18.100</td>\n",
       "      <td>18.200</td>\n",
       "      <td>17.700</td>\n",
       "      <td>17.400</td>\n",
       "      <td>17.00</td>\n",
       "      <td>16.100</td>\n",
       "      <td>15.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9900</td>\n",
       "      <td>8.7100</td>\n",
       "      <td>8.3900</td>\n",
       "      <td>8.280</td>\n",
       "      <td>7.490</td>\n",
       "      <td>8.030</td>\n",
       "      <td>7.690</td>\n",
       "      <td>7.31</td>\n",
       "      <td>7.280</td>\n",
       "      <td>6.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               country  1800  1801  1802  1803  1804  1805  1806    1807  \\\n",
       "0          Afghanistan   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "1              Albania   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "2              Algeria   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "3              Andorra   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "4               Angola   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "5  Antigua and Barbuda   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "6            Argentina   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "7              Armenia   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "8            Australia   NaN   NaN   NaN   NaN   NaN   NaN   NaN     NaN   \n",
       "9              Austria   NaN   NaN   NaN   NaN   NaN   NaN   NaN  0.0517   \n",
       "\n",
       "   1808   ...       2005     2006     2007    2008    2009    2010    2011  \\\n",
       "0   NaN   ...     0.0529   0.0637   0.0854   0.154   0.242   0.294   0.412   \n",
       "1   NaN   ...     1.3800   1.2800   1.3000   1.460   1.480   1.560   1.790   \n",
       "2   NaN   ...     3.2200   2.9900   3.1900   3.160   3.420   3.300   3.290   \n",
       "3   NaN   ...     7.3000   6.7500   6.5200   6.430   6.120   6.120   5.870   \n",
       "4   NaN   ...     0.9800   1.1000   1.2000   1.180   1.230   1.240   1.250   \n",
       "5   NaN   ...     4.8100   4.9100   5.1400   5.190   5.450   5.540   5.360   \n",
       "6   NaN   ...     4.1400   4.4300   4.3800   4.680   4.410   4.560   4.600   \n",
       "7   NaN   ...     1.4600   1.4800   1.7300   1.910   1.510   1.470   1.710   \n",
       "8   NaN   ...    17.3000  17.8000  17.8000  18.100  18.200  17.700  17.400   \n",
       "9   NaN   ...     8.9900   8.7100   8.3900   8.280   7.490   8.030   7.690   \n",
       "\n",
       "    2012    2013    2014  \n",
       "0   0.35   0.316   0.299  \n",
       "1   1.68   1.730   1.960  \n",
       "2   3.46   3.510   3.720  \n",
       "3   5.92   5.900   5.830  \n",
       "4   1.33   1.250   1.290  \n",
       "5   5.42   5.360   5.380  \n",
       "6   4.57   4.460   4.750  \n",
       "7   1.98   1.900   1.900  \n",
       "8  17.00  16.100  15.400  \n",
       "9   7.31   7.280   6.800  \n",
       "\n",
       "[10 rows x 216 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv file as a dataframe\n",
    "df_co2 = pd.read_csv('Data/co2_emissions_tonnes_per_person.csv')\n",
    "\n",
    "#print first 10 lines\n",
    "df_co2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 216)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shape to see the amount of countries (x) and amount of years (y)\n",
    "df_co2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country      0\n",
       "1800       187\n",
       "1801       187\n",
       "1802       185\n",
       "1803       187\n",
       "1804       186\n",
       "1805       187\n",
       "1806       187\n",
       "1807       186\n",
       "1808       187\n",
       "1809       187\n",
       "1810       186\n",
       "1811       186\n",
       "1812       186\n",
       "1813       186\n",
       "1814       186\n",
       "1815       186\n",
       "1816       186\n",
       "1817       186\n",
       "1818       186\n",
       "1819       185\n",
       "1820       185\n",
       "1821       185\n",
       "1822       185\n",
       "1823       185\n",
       "1824       185\n",
       "1825       185\n",
       "1826       185\n",
       "1827       185\n",
       "1828       185\n",
       "          ... \n",
       "1985        20\n",
       "1986        20\n",
       "1987        20\n",
       "1988        20\n",
       "1989        20\n",
       "1990        16\n",
       "1991        15\n",
       "1992         4\n",
       "1993         4\n",
       "1994         3\n",
       "1995         3\n",
       "1996         3\n",
       "1997         3\n",
       "1998         3\n",
       "1999         3\n",
       "2000         3\n",
       "2001         3\n",
       "2002         2\n",
       "2003         2\n",
       "2004         2\n",
       "2005         2\n",
       "2006         2\n",
       "2007         1\n",
       "2008         1\n",
       "2009         1\n",
       "2010         1\n",
       "2011         1\n",
       "2012         0\n",
       "2013         0\n",
       "2014         0\n",
       "Length: 216, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values\n",
    "df_co2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the dataset consists of a very wide range of years, the amount of missing values is considerably high in the years before the 90's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicated rows\n",
    "df_co2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Development Index (HDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Australia</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Austria</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               country   1990   1991   1992   1993   1994   1995   1996  \\\n",
       "0          Afghanistan  0.295  0.300  0.309  0.305  0.300  0.324  0.328   \n",
       "1              Albania  0.635  0.618  0.603  0.608  0.616  0.628  0.637   \n",
       "2              Algeria  0.577  0.581  0.587  0.591  0.595  0.600  0.609   \n",
       "3              Andorra    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4               Angola    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "5  Antigua and Barbuda    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "6            Argentina  0.705  0.713  0.720  0.725  0.728  0.731  0.738   \n",
       "7              Armenia  0.634  0.628  0.595  0.593  0.597  0.603  0.609   \n",
       "8            Australia  0.866  0.867  0.871  0.874  0.876  0.885  0.888   \n",
       "9              Austria  0.794  0.798  0.804  0.806  0.812  0.816  0.819   \n",
       "\n",
       "    1997   1998  ...     2006   2007   2008   2009   2010   2011   2012  \\\n",
       "0  0.332  0.335  ...    0.415  0.433  0.434  0.448  0.454  0.463  0.470   \n",
       "1  0.636  0.646  ...    0.703  0.713  0.721  0.725  0.738  0.752  0.759   \n",
       "2  0.617  0.627  ...    0.690  0.697  0.705  0.714  0.724  0.732  0.737   \n",
       "3    NaN    NaN  ...      NaN    NaN    NaN    NaN  0.819  0.819  0.843   \n",
       "4    NaN    NaN  ...    0.454  0.468  0.480  0.488  0.495  0.508  0.523   \n",
       "5    NaN    NaN  ...    0.781  0.786  0.788  0.783  0.782  0.778  0.781   \n",
       "6  0.746  0.753  ...    0.788  0.792  0.794  0.802  0.816  0.822  0.823   \n",
       "7  0.618  0.632  ...    0.707  0.721  0.725  0.720  0.729  0.732  0.736   \n",
       "8  0.891  0.894  ...    0.918  0.921  0.925  0.927  0.927  0.930  0.933   \n",
       "9  0.823  0.833  ...    0.860  0.864  0.870  0.872  0.880  0.884  0.887   \n",
       "\n",
       "    2013   2014   2015  \n",
       "0  0.476  0.479  0.479  \n",
       "1  0.761  0.762  0.764  \n",
       "2  0.741  0.743  0.745  \n",
       "3  0.850  0.857  0.858  \n",
       "4  0.527  0.531  0.533  \n",
       "5  0.782  0.784  0.786  \n",
       "6  0.825  0.826  0.827  \n",
       "7  0.739  0.741  0.743  \n",
       "8  0.936  0.937  0.939  \n",
       "9  0.892  0.892  0.893  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv file as a dataframe\n",
    "df_hdi = pd.read_csv('Data/hdi_human_development_index.csv')\n",
    "\n",
    "#print first 10 lines\n",
    "df_hdi.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shape to see the amount of countries (x) and amount of years (y)\n",
    "df_hdi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is already very small compared to the Co2 emissions data set that consists of records from the last 216 years compared to 27 in this one. \n",
    "Another big difference to consider is that the biggest year also differs, here is 2015 but in the Co2 emissions dataset was 2014. \n",
    "I'll check the next datasets, but so far **the year range of the analysis should go from 1990 until 2014**. \n",
    "\n",
    "There's also a **difference in the amount of couentries** that should also be compared and unified before proceding with the analysis phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country     0\n",
       "1990       44\n",
       "1991       44\n",
       "1992       44\n",
       "1993       44\n",
       "1994       44\n",
       "1995       40\n",
       "1996       40\n",
       "1997       40\n",
       "1998       40\n",
       "1999       37\n",
       "2000       20\n",
       "2001       20\n",
       "2002       20\n",
       "2003       18\n",
       "2004       15\n",
       "2005        6\n",
       "2006        6\n",
       "2007        6\n",
       "2008        6\n",
       "2009        6\n",
       "2010        0\n",
       "2011        0\n",
       "2012        0\n",
       "2013        0\n",
       "2014        0\n",
       "2015        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values\n",
    "df_hdi.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional to the missing years, this dataset also has several missing values, especially before the year 2000 where almost 24%\n",
    "of the countries have missing data (44 out of 187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicated rows\n",
    "df_hdi.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forest coverage(%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'forest_coverage_percent.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0e510eaaefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the csv file as a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'forest_coverage_percent.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print first 10 lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_fc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'forest_coverage_percent.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Import the csv file as a dataframe\n",
    "df_fc = pd.read_csv('forest_coverage_percent.csv')\n",
    "\n",
    "#print first 10 lines\n",
    "df_fc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print shape to see the amount of countries (x) and amount of years (y)\n",
    "df_fc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the amount of countries matches with the Co2 indicator, I'll have to check if the values match. But the range of years is considerable lesss, and it matches the HDI dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values\n",
    "df_fc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows\n",
    "df_fc.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Democracy score (Polity)\n",
    "\n",
    "This dataset was obtained from the official website, because it was more updated that the version provided by gapminder. \n",
    "The main difference is found in the format of the file, it's provided as an .xls format instead of .csv, contains more variables and the year is listed as one more column instead of being the first row of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the excel file as a dataframe\n",
    "df_polity = pd.read_excel('Data/p4v2018.xls')\n",
    "\n",
    "#print first 10 lines\n",
    "df_polity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the dataset is formatted diferently than the others, so it will have to be adapted to the format\n",
    "# check columns in the dataset\n",
    "df_polity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indicator we need, and that was listed in Gapminder is polity2\n",
    "# Only the columns Country, year and polity2 are needed\n",
    "df_polity = df_polity[['country','year','polity2']]\n",
    "df_polity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Due to the difference in format I can't use shape to determine amount of years and countries\n",
    "df_polity.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get year range\n",
    "print(df_polity['year'].min(),\"-\", df_polity['year'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is the one that a greater year range and also more countries than the other, I'll have to limit it for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows\n",
    "df_polity.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the duplicated line\n",
    "df_polity[df_polity.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there's a line duplicated, the problem is that the dataset has countries, like Yugoslavia that just appeared, that don't exist anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check amount of \"valid\" countries in the dataset\n",
    "# filtering with year == 2014 because that will be the end of the year range I'll use\n",
    "df_polity[df_polity.year == 2014].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values\n",
    "df_polity.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polity[df_polity.year >= 1990].isnull().any(axis=1)\n",
    "\n",
    "#df_polity[df_polity.isnull().any(axis=1)].query('year > 1990')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polity.isnull().values.any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip**: You should _not_ perform too many operations in each cell. Create cells freely to explore your data. One option that you can take with this project is to do a lot of explorations in an initial notebook. These don't have to be organized, but make sure you use enough comments to understand the purpose of each code cell. Then, after you're done with your analysis, create a duplicate notebook where you will trim the excess and organize your steps so that you have a flowing, cohesive report.\n",
    "\n",
    "> **Tip**: Make sure that you keep your reader informed on the steps that you are taking in your investigation. Follow every code cell, or every set of related code cells, with a markdown cell to describe to the reader what was found in the preceding cell(s). Try to make it so that the reader can then understand what they will be seeing in the following cell(s).\n",
    "\n",
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the year range to all datasets\n",
    "\n",
    "Only the data belonging to the year range between 1990 until 2014 will be analyzed, the remaining years will be dropped from each dataframe. \n",
    "In the case of the first 3 indicators (Co2, fc and HDI) it can be done by selecting the columns that correspond to the years withing the year range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop the columns outside of the year range (1990-2014)\n",
    "df_co2 = df_co2.drop(df_co2.loc[:,'1800':'1989'].columns, axis = 1) \n",
    "df_co2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll use the list of columns to filter the year range in the other dataframes\n",
    "columns = list(df_co2.columns) \n",
    "\n",
    "df_hdi = df_hdi[columns]\n",
    "df_fc = df_fc[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new structure\n",
    "df_hdi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new structure\n",
    "df_fc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of polity, since the years are not columns as in the previous dataframes, I'll use pandas query to filter only the rows belonging to the desired year range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polity = df_polity.query('year > 1989 and year < 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing data\n",
    "df_polity.dropna(subset=['polity2'],inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unify list of countries\n",
    "Although every dataframe had a similar amount of countries, it has to be checked if they match. \n",
    "\n",
    "Aditionally, in the case of the polity indicator, I'll remove all countries that in the last year of analysis have no data, I'll assume these countries don't have a current political system, as it's with Yugoslavia, the one duplicated row. \n",
    "\n",
    "I'll use the valid countries from the polity indicator as the initial list of valid countries for the analysis. \n",
    "\n",
    "Then, I'll remove the countries not existing in the other dataframes. \n",
    "\n",
    "Lastly, I'll use that list to filter the valid data from the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the countries that have data in the year 2014 \n",
    "# This will also remove the one duplicate we found\n",
    "\n",
    "countries  = df_polity.query('year == 2014')\n",
    "countries = countries[['country']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the countries that exist in the other datasets\n",
    "\n",
    "countries = countries[countries.country.isin(df_co2['country'])]\n",
    "countries = countries[countries.country.isin(df_fc['country'])]\n",
    "countries = countries[countries.country.isin(df_hdi['country'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the amount of valid countries for the analysis\n",
    "countries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in each indicator only the countries that have data in all datasets\n",
    "df_polity = df_polity[df_polity.country.isin(countries['country'])]\n",
    "df_co2 = df_fc[df_fc.country.isin(countries['country'])]\n",
    "df_fc = df_fc[df_fc.country.isin(countries['country'])]\n",
    "df_hdi = df_fc[df_fc.country.isin(countries['country'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To facilitate the analysis the year has to be used as the column names, \n",
    "# and the polity score will be found in the intersection between the country and the year\n",
    "\n",
    "df_polity_pivot = pd.pivot_table(df_polity, values='polity2', index=['country'],\n",
    "                    columns=['year'], dropna = True)\n",
    "\n",
    "df_polity_pivot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll drop the multiindex to have all datasets formated the same way\n",
    "df_polity_pivot.reset_index(drop=False, col_level=1, inplace=True)\n",
    "df_polity_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polity_pivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n",
    "\n",
    "### Research Question 1 (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this, and more code cells, to explore your data. Don't forget to add\n",
    "#   Markdown cells to document your observations and findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2  (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed. Make sure that you are clear with regards to the limitations of your exploration. If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the rubric (found on the project submission page at the end of the lesson). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "## Submitting your Project \n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from subprocess import call\n",
    "#call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
